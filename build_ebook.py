import os
import subprocess
from jinja2 import Environment
import re
import urllib.request
import urllib.parse
import hashlib
import mimetypes
import yaml

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHAPTERS_DIR = os.path.join(BASE_DIR, "chapters")
BUILD_DIR = os.path.join(BASE_DIR, "build")
OUTPUT_TEX = os.path.join(BUILD_DIR, "book.tex")
OUTPUT_PDF = os.path.join(BASE_DIR, "book.pdf")
MEDIA_DIR = os.path.join(BUILD_DIR, "media")
DEFAULT_IMAGE = os.path.join(BASE_DIR, "images/empty.png")
IMAGE_CACHE = os.path.join(BASE_DIR, "images/cache")

def collect_parts_from_yaml():
    yaml_path = os.path.join(BASE_DIR, "book.yaml")
    if not os.path.exists(yaml_path):
        return None

    with open(yaml_path, "r", encoding="utf-8") as f:
        book_data = yaml.safe_load(f)

    parts = []
    for part in book_data.get("parts", []):
        part_name = part.get("name") or os.path.basename(part["path"])
        part_path = os.path.join(CHAPTERS_DIR, part["path"])
        readme_path = os.path.join(part_path, "README.md")
        readme = readme_path if os.path.exists(readme_path) else ""

        chapters = []
        for ch in part.get("chapters", []):
            ch_name = ch.get("name") or os.path.splitext(os.path.basename(ch["file"]))[0]
            ch_file = os.path.join(part_path, ch["file"])
            if os.path.exists(ch_file):
                chapters.append({"title": ch_name, "path": ch_file})
            else:
                print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°ç« èŠ‚æ–‡ä»¶ {ch_file}")

        parts.append({
            "title": part_name,
            "readme": readme,
            "chapters": [c["path"] for c in chapters],
            "chapter_titles": {c["path"]: c["title"] for c in chapters}
        })

    return parts

def collect_parts_auto():
    parts = []
    for item in sorted(os.listdir(CHAPTERS_DIR)):
        part_path = os.path.join(CHAPTERS_DIR, item)
        if os.path.isdir(part_path) and not item.startswith("_"):
            part = {"title": item, "readme": "", "chapters": []}
            for f in sorted(os.listdir(part_path)):
                if f.lower() == "readme.md":
                    part["readme"] = os.path.join(part_path, f)
                elif f.endswith(".md"):
                    part["chapters"].append(os.path.join(part_path, f))
            parts.append(part)
    return parts

# âœ… ç»Ÿä¸€æ¥å£ï¼šä¼˜å…ˆä» book.yaml è¯»å–ï¼Œå¦åˆ™æ‰«æ
def collect_parts():
    parts = collect_parts_from_yaml()
    if parts:
        print("ğŸ“˜ ä½¿ç”¨ book.yaml ä¸­å®šä¹‰çš„ç« èŠ‚ç»“æ„")
        return parts
    else:
        print("ğŸ“— æœªæ‰¾åˆ° book.yamlï¼Œè‡ªåŠ¨æ‰«æ chapters ç›®å½•ç»“æ„")
        return collect_parts_auto()


def _download_image_with_cache(url, media_dir):
    """ä¸‹è½½è¿œç¨‹å›¾ç‰‡åˆ° media_dirï¼Œè¿”å›æœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºBUILD_DIRï¼‰ï¼Œæˆ– Noneã€‚"""

    os.makedirs(IMAGE_CACHE, exist_ok=True)
    os.makedirs(media_dir, exist_ok=True)

    # æ ¹æ® URL ç”Ÿæˆ hash
    h = hashlib.sha1(url.encode("utf-8")).hexdigest()[:12]

    # -------- (1) å°è¯•ä»ç¼“å­˜ç›®å½•ä¸­æ‰¾åˆ°ç›¸åŒ hash çš„æ–‡ä»¶ï¼ˆä¸è®ºæ‰©å±•åï¼‰--------
    cached_file = None
    for f in os.listdir(IMAGE_CACHE):
        if f.startswith(f"img-{h}"):
            cached_file = os.path.join(IMAGE_CACHE, f)
            break

    if cached_file and os.path.exists(cached_file):
        ext = os.path.splitext(cached_file)[1]
        out_path = os.path.join(media_dir, f"img-{h}{ext}")
        if not os.path.exists(out_path):
            try:
                with open(cached_file, "rb") as src, open(out_path, "wb") as dst:
                    dst.write(src.read())
            except Exception as e:
                print("warn: å¤åˆ¶ç¼“å­˜å›¾ç‰‡å¤±è´¥:", cached_file, e)
                return None
        rel = os.path.relpath(out_path, BUILD_DIR).replace("\\", "/")
        print("ä½¿ç”¨ç¼“å­˜å›¾ç‰‡:", url, "->", rel)
        return rel

    # -------- (2) ä¸‹è½½å›¾ç‰‡ --------
    default_image_path = os.path.relpath(DEFAULT_IMAGE, BUILD_DIR).replace("\\", "/")
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=30) as resp:
            data = resp.read()
            ctype = resp.headers.get("Content-Type", "")
    except Exception as e:
        print("warn: ä¸‹è½½å›¾ç‰‡å¤±è´¥:", url, e)
        return default_image_path

    # -------- (3) è‡ªåŠ¨æ¨æ–­æ‰©å±•å --------
    # ä¼˜å…ˆä» Content-Type åˆ¤æ–­
    ext = mimetypes.guess_extension(ctype.split(";")[0].strip()) if ctype else None
    # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä» URL åç¼€åˆ¤æ–­
    if not ext:
        parsed = urllib.parse.urlparse(url)
        path_ext = os.path.splitext(parsed.path)[1]
        if path_ext and len(path_ext) <= 5:
            ext = path_ext
    # å¦‚æœä»æ— æ‰©å±•åï¼Œé»˜è®¤ jpg
    if not ext:
        ext = ".jpg"

    fname = f"img-{h}{ext}"
    out_path = os.path.join(media_dir, fname)
    cached_path = os.path.join(IMAGE_CACHE, fname)

    # -------- (4) å†™å…¥æ–‡ä»¶å¹¶ç¼“å­˜ --------
    try:
        with open(out_path, "wb") as f, open(cached_path, "wb") as cache_f:
            f.write(data)
            cache_f.write(data)
        rel = os.path.relpath(out_path, BUILD_DIR).replace("\\", "/")
        print("ä¸‹è½½æ–°å›¾ç‰‡:", url, "->", rel)
        return rel
    except Exception as e:
        print("warn: å†™æ–‡ä»¶å¤±è´¥:", out_path, e)
        return default_image_path


# def _download_image_with_cache(url, media_dir):
#     """ä¸‹è½½è¿œç¨‹å›¾ç‰‡åˆ° media_dirï¼Œè¿”å›æœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº BASE_DIRï¼‰ï¼Œæˆ– None."""

#     # æ£€æŸ¥ç¼“å­˜ç›®å½•
#     os.makedirs(IMAGE_CACHE, exist_ok=True)
#     os.makedirs(media_dir, exist_ok=True)

#     # ç”¨ URL çš„ hash ç”Ÿæˆæ–‡ä»¶åï¼Œé¿å…éæ³•å­—ç¬¦
#     h = hashlib.sha1(url.encode("utf-8")).hexdigest()[:12]
#     fname = f"img-{h}"

#     # æ£€æŸ¥ç¼“å­˜
#     cached_path = os.path.join(IMAGE_CACHE, fname)
#     if os.path.exists(cached_path):
#         # å¤åˆ¶åˆ° media_dir
#         out_path = os.path.join(media_dir, fname)
#         if not os.path.exists(out_path):
#             try:
#                 with open(cached_path, "rb") as src, open(out_path, "wb") as dst:
#                     dst.write(src.read())
#             except Exception as e:
#                 print("warn: å¤åˆ¶ç¼“å­˜å›¾ç‰‡å¤±è´¥:", cached_path, e)
#                 return None
#         # è¿”å›ç›¸å¯¹äº BUILD_DIR çš„è·¯å¾„ï¼ˆä¾¿äº pandoc ç”Ÿæˆçš„ tex è·¯å¾„ç›´æ¥å¯ç”¨ï¼‰
#         rel = os.path.relpath(out_path, BUILD_DIR)
#         print("ä½¿ç”¨ç¼“å­˜å›¾ç‰‡:", url, "->", rel)
#         return rel.replace("\\", "/")

#     default_image_path = os.path.relpath(DEFAULT_IMAGE, BUILD_DIR).replace("\\", "/")
#     try:
#         req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
#         with urllib.request.urlopen(req, timeout=30) as resp:
#             data = resp.read()
#             ctype = resp.headers.get("Content-Type", "")
#     except Exception as e:
#         print("warn: ä¸‹è½½å›¾ç‰‡å¤±è´¥:", url, e)
#         return default_image_path

#     out_path = os.path.join(media_dir, fname)
#     try:
#         with open(out_path, "wb") as f, open(cached_path, "wb") as cache_f:
#             f.write(data)
#             cache_f.write(data)
#         # è¿”å›ç›¸å¯¹äº BUILD_DIR çš„è·¯å¾„ï¼ˆä¾¿äº pandoc ç”Ÿæˆçš„ tex è·¯å¾„ç›´æ¥å¯ç”¨ï¼‰
#         rel = os.path.relpath(out_path, BUILD_DIR)
#         return rel.replace("\\", "/")
#     except Exception as e:
#         print("warn: å†™æ–‡ä»¶å¤±è´¥:", out_path, e)
#         return default_image_path

def _localize_images_in_md(md_path):
    """è¯»å– md æ–‡ä»¶ï¼Œä¸‹è½½æ‰€æœ‰è¿œç¨‹å›¾ç‰‡ï¼ˆå¸¸è§çš„ ![alt](url) ä»¥åŠ <img src="url">ï¼‰ï¼Œ
       æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„ï¼Œå†™å…¥ build ä¸‹çš„ä¸´æ—¶ md å¹¶è¿”å›å…¶è·¯å¾„ã€‚
    """
    with open(md_path, "r", encoding="utf-8") as f:
        text = f.read()

    # ç¡®ä¿ media ç›®å½•å­˜åœ¨
    os.makedirs(MEDIA_DIR, exist_ok=True)

    # 1) å¤„ç†æ ‡å‡† Markdown å›¾ç‰‡è¯­æ³• ![alt](url "title")
    #    è¿™ä¸ª regex é€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µï¼ˆæ³¨æ„ï¼šè‹¥ url åŒ…å«æœªé…å¯¹çš„æ‹¬å·ï¼Œå¯èƒ½å¤±æ•ˆï¼‰
    md_img_re = re.compile(r'!\[([^\]]*)\]\((\S+?)(?:\s+"[^"]*")?\)')

    def md_repl(m):
        alt = m.group(1)
        url = m.group(2).strip()
        # å¦‚æœ url æœ‰å°–æ‹¬å· <...>, å»æ‰
        if url.startswith("<") and url.endswith(">"):
            url = url[1:-1]
        if url.lower().startswith("http"):
            local = _download_image_with_cache(url, MEDIA_DIR)
            if local:
                return f'![{alt}]({local})'
            else:
                return m.group(0)  # ä¸‹è½½å¤±è´¥ï¼Œä¿æŒåŸæ ·
        else:
            return m.group(0)

    text = md_img_re.sub(md_repl, text)

    # 2) å¤„ç† HTML <img src="..."> çš„æƒ…å†µï¼ˆNotion å¯¼å‡ºæœ‰æ—¶ä¼šç”¨è¿™ç§ï¼‰
    html_img_re = re.compile(r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>')
    def html_repl(m):
        url = m.group(1).strip()
        if url.lower().startswith("http"):
            local = _download_image_with_cache(url, MEDIA_DIR)
            if local:
                # ç”¨ markdown è¯­æ³•æ›¿æ¢ä¸ºæ™®é€šå›¾ç‰‡å¼•ç”¨ï¼ˆpandoc æ›´å®¹æ˜“å¤„ç†ï¼‰
                return f'![]({local})'
            else:
                return m.group(0)
        else:
            return m.group(0)
    text = html_img_re.sub(html_repl, text)

    # å†™å…¥åˆ° build ä¸‹çš„ä¸´æ—¶ mdï¼ˆæ–‡ä»¶åä¿æŒä¸å˜ï¼‰
    out_md = os.path.join(BUILD_DIR, os.path.basename(md_path))
    with open(out_md, "w", encoding="utf-8") as f:
        f.write(text)
    return out_md

# Pandoc Markdown â†’ LaTeX
def md_to_latex(md_file):
    """
    å°† Markdown è½¬ LaTeXï¼Œä¿è¯å›¾ç‰‡è·¯å¾„å¯ç›´æ¥åœ¨ build/book.tex ä¸­ç”Ÿæˆ PDFã€‚
    """
    # 1. ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¹¶æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„
    tmp_md = _localize_images_in_md(md_file)

    # 2. è°ƒç”¨ Pandoc è½¬ LaTeX
    result = subprocess.run(
        [
            "pandoc", tmp_md,
            "-f", "markdown",
            "-t", "latex",
            "--metadata", "link-citations=false",
            "--no-highlight",
            "--top-level-division=section",
            "--wrap=none",
            "--listings"
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        encoding="utf-8"
    )
    if result.returncode != 0:
        print(f"Pandoc è½¬ LaTeX å‡ºé”™: {result.stderr}")
        return ""
    tex = result.stdout

    # 3. ç§»é™¤æ‰€æœ‰ \label{...} é˜²æ­¢ä¸­æ–‡æŠ¥é”™
    tex = re.sub(r'\\label\{.*?\}', '', tex)

    # 4. æ›¿æ¢ç‰¹æ®Šç¬¦å· â–ª â†’ \textbullet{}
    tex = tex.replace("â–ª", "\\textbullet{}")

    # 5. ä¿®æ­£ \includegraphicsï¼Œç»Ÿä¸€åŒ…è£¹ä¸€å±‚ \pandocbounded
    def fix_graphics(match):
        # åŸè·¯å¾„
        path = match.group(2).strip()

        # è·¯å¾„è½¬ä¸ºç»å¯¹è·¯å¾„å†ç›¸å¯¹äº BASE_DIR
        abs_path = os.path.abspath(os.path.join(BUILD_DIR, path)) if not os.path.isabs(path) else path
        rel_path = os.path.relpath(abs_path, BASE_DIR).replace("\\", "/")
        # è½¬ä¹‰ä¸‹åˆ’çº¿
        rel_path = rel_path.replace("_", "\\_")

        # å›ºå®šé€‰é¡¹
        options = "[keepaspectratio,width=\\linewidth]"

        # è¿”å›å•å±‚ pandocbounded åŒ…è£¹
        return f"\\includegraphics{options}{{{rel_path}}}"

    tex = re.sub(
        r'\\includegraphics(\[.*?\])\{(.*?)\}',
        fix_graphics,
        tex
    )

    return tex

# æ¸²æŸ“ LaTeX æ¨¡æ¿
def render_tex(parts):
    template_path = os.path.join(BASE_DIR, "template", "template.tex")
    with open(template_path, "r", encoding="utf-8") as f:
        template_content = f.read()
    env = Environment(
        block_start_string = '<%',
        block_end_string = '%>',
        variable_start_string = '<<',
        variable_end_string = '>>',
        comment_start_string = '<#',
        comment_end_string = '#>',
        autoescape = False
    )
    template = env.from_string(template_content)
    return template.render(parts=parts)

def main():
    os.makedirs(os.path.join(BASE_DIR, "build"), exist_ok=True)
    parts = collect_parts()

    # ç”Ÿæˆ LaTeX å†…å®¹
    for part in parts:
        part["readme_tex"] = md_to_latex(part["readme"]) if part["readme"] else ""
        chapters_data = []
        for chap in part["chapters"]: # chap æ˜¯ç« èŠ‚(md)çš„å®Œæ•´è·¯å¾„
            file_name = os.path.splitext(os.path.basename(chap))[0]
            tex = md_to_latex(chap)
            # è·å–ç« èŠ‚æ ‡é¢˜
            first_line = tex.strip().split("\n")[0]
            title = first_line.replace("\\section{", "").replace("}", "") if first_line.startswith("\\section") else file_name
            chapters_data.append({"title": title, "tex": tex})
        part["chapters_data"] = chapters_data

    tex_content = render_tex(parts)
    with open(OUTPUT_TEX, "w", encoding="utf-8") as f:
        f.write(tex_content)

    # XeLaTeX ç”Ÿæˆ PDF
    subprocess.run([
        "xelatex",
        "-interaction=nonstopmode",
        "-output-directory", os.path.join(BASE_DIR, "build"),
        OUTPUT_TEX
    ])
    generated_pdf = os.path.join(BASE_DIR, "build", "book.pdf")
    if os.path.exists(generated_pdf):
        os.replace(generated_pdf, OUTPUT_PDF)
        print(f"PDF å·²ç”Ÿæˆ: {OUTPUT_PDF}")

if __name__ == "__main__":
    main()
