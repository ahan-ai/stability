import os
import subprocess
from jinja2 import Environment
import re
import urllib.request
import urllib.parse
import hashlib
import mimetypes
import yaml

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHAPTERS_DIR = os.path.join(BASE_DIR, "chapters")
BUILD_DIR = os.path.join(BASE_DIR, "build")
OUTPUT_TEX = os.path.join(BUILD_DIR, "book.tex")
OUTPUT_PDF = os.path.join(BASE_DIR, "book.pdf")
MEDIA_DIR = os.path.join(BUILD_DIR, "media")
DEFAULT_IMAGE = os.path.join(BASE_DIR, "images/empty.png")
IMAGE_CACHE = os.path.join(BASE_DIR, "images/cache")

def collect_parts_from_yaml():
    yaml_path = os.path.join(BASE_DIR, "book.yaml")
    if not os.path.exists(yaml_path):
        return None

    with open(yaml_path, "r", encoding="utf-8") as f:
        book_data = yaml.safe_load(f)

    parts = []
    for part in book_data.get("parts", []):
        part_name = part.get("name") or os.path.basename(part["path"])
        part_path = os.path.join(CHAPTERS_DIR, part["path"])
        readme_path = os.path.join(part_path, "README.md")
        readme = readme_path if os.path.exists(readme_path) else ""

        chapters = []
        for ch in part.get("chapters", []):
            ch_name = ch.get("name") or os.path.splitext(os.path.basename(ch["file"]))[0]
            print("ch_name:", ch_name)
            ch_file = os.path.join(part_path, ch["file"])
            if os.path.exists(ch_file):
                chapters.append({"title": ch_name, "path": ch_file})
            else:
                print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°ç« èŠ‚æ–‡ä»¶ {ch_file}")

        parts.append({
            "title": part_name,
            "readme": readme,
            "chapters": [c["path"] for c in chapters],
            "chapter_titles": [c["title"] for c in chapters]
        })

    return parts

def collect_parts_auto():
    parts = []
    for item in sorted(os.listdir(CHAPTERS_DIR)):
        part_path = os.path.join(CHAPTERS_DIR, item)
        if os.path.isdir(part_path) and not item.startswith("_"):
            part = {"title": item, "readme": "", "chapters": []}
            for f in sorted(os.listdir(part_path)):
                if f.lower() == "readme.md":
                    part["readme"] = os.path.join(part_path, f)
                elif f.endswith(".md"):
                    part["chapters"].append(os.path.join(part_path, f))
            parts.append(part)
    return parts

# âœ… ç»Ÿä¸€æ¥å£ï¼šä¼˜å…ˆä» book.yaml è¯»å–ï¼Œå¦åˆ™æ‰«æ
def collect_parts():
    parts = collect_parts_from_yaml()
    if parts:
        print("ğŸ“˜ ä½¿ç”¨ book.yaml ä¸­å®šä¹‰çš„ç« èŠ‚ç»“æ„")
        return parts
    else:
        print("ğŸ“— æœªæ‰¾åˆ° book.yamlï¼Œè‡ªåŠ¨æ‰«æ chapters ç›®å½•ç»“æ„")
        return collect_parts_auto()


def _download_image_with_cache(url, media_dir):
    """ä¸‹è½½è¿œç¨‹å›¾ç‰‡åˆ° media_dirï¼Œè¿”å›æœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºBUILD_DIRï¼‰ï¼Œæˆ– Noneã€‚"""

    os.makedirs(IMAGE_CACHE, exist_ok=True)
    os.makedirs(media_dir, exist_ok=True)

    # æ ¹æ® URL ç”Ÿæˆ hash
    h = hashlib.sha1(url.encode("utf-8")).hexdigest()[:12]

    # -------- (1) å°è¯•ä»ç¼“å­˜ç›®å½•ä¸­æ‰¾åˆ°ç›¸åŒ hash çš„æ–‡ä»¶ï¼ˆä¸è®ºæ‰©å±•åï¼‰--------
    cached_file = None
    for f in os.listdir(IMAGE_CACHE):
        if f.startswith(f"img-{h}"):
            cached_file = os.path.join(IMAGE_CACHE, f)
            break

    if cached_file and os.path.exists(cached_file):
        ext = os.path.splitext(cached_file)[1]
        out_path = os.path.join(media_dir, f"img-{h}{ext}")
        if not os.path.exists(out_path):
            try:
                with open(cached_file, "rb") as src, open(out_path, "wb") as dst:
                    dst.write(src.read())
            except Exception as e:
                print("warn: å¤åˆ¶ç¼“å­˜å›¾ç‰‡å¤±è´¥:", cached_file, e)
                return None
        rel = os.path.relpath(out_path, BUILD_DIR).replace("\\", "/")
        print("ä½¿ç”¨ç¼“å­˜å›¾ç‰‡:", url, "->", rel)
        return rel

    # -------- (2) ä¸‹è½½å›¾ç‰‡ --------
    default_image_path = os.path.relpath(DEFAULT_IMAGE, BUILD_DIR).replace("\\", "/")
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=30) as resp:
            data = resp.read()
            ctype = resp.headers.get("Content-Type", "")
    except Exception as e:
        print("warn: ä¸‹è½½å›¾ç‰‡å¤±è´¥:", url, e)
        return default_image_path

    # -------- (3) è‡ªåŠ¨æ¨æ–­æ‰©å±•å --------
    # ä¼˜å…ˆä» Content-Type åˆ¤æ–­
    ext = mimetypes.guess_extension(ctype.split(";")[0].strip()) if ctype else None
    # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä» URL åç¼€åˆ¤æ–­
    if not ext:
        parsed = urllib.parse.urlparse(url)
        path_ext = os.path.splitext(parsed.path)[1]
        if path_ext and len(path_ext) <= 5:
            ext = path_ext
    # å¦‚æœä»æ— æ‰©å±•åï¼Œé»˜è®¤ jpg
    if not ext:
        ext = ".jpg"

    fname = f"img-{h}{ext}"
    out_path = os.path.join(media_dir, fname)
    cached_path = os.path.join(IMAGE_CACHE, fname)

    # -------- (4) å†™å…¥æ–‡ä»¶å¹¶ç¼“å­˜ --------
    try:
        with open(out_path, "wb") as f, open(cached_path, "wb") as cache_f:
            f.write(data)
            cache_f.write(data)
        rel = os.path.relpath(out_path, BUILD_DIR).replace("\\", "/")
        print("ä¸‹è½½æ–°å›¾ç‰‡:", url, "->", rel)
        return rel
    except Exception as e:
        print("warn: å†™æ–‡ä»¶å¤±è´¥:", out_path, e)
        return default_image_path


def _localize_images_in_md(md_path):
    """
    è¯»å– md æ–‡ä»¶ï¼š
      - ä¸‹è½½è¿œç¨‹å›¾ç‰‡
      - å¤åˆ¶æœ¬åœ°å›¾ç‰‡åˆ° build/media
      - æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„
    è¿”å›æ–° md çš„è·¯å¾„ï¼ˆä½äº build/ ä¸‹ï¼‰ã€‚
    """
    with open(md_path, "r", encoding="utf-8") as f:
        text = f.read()

    # ç¡®ä¿ media ç›®å½•å­˜åœ¨
    os.makedirs(MEDIA_DIR, exist_ok=True)
    md_dir = os.path.dirname(md_path)

    def _copy_local_image(src_path):
        """
        å¤åˆ¶æœ¬åœ°å›¾ç‰‡åˆ° MEDIA_DIR ä¸‹ï¼Œè¿”å›ç›¸å¯¹ build çš„è·¯å¾„ã€‚
        """
        if not os.path.isabs(src_path):
            src_path = os.path.join(md_dir, src_path)
        src_path = os.path.normpath(src_path)

        if not os.path.exists(src_path):
            print(f"âš ï¸  æ‰¾ä¸åˆ°æœ¬åœ°å›¾ç‰‡: {src_path}")
            return None

        # ä¿ç•™æ–‡ä»¶åï¼Œç”¨å“ˆå¸Œé¿å…å†²çª
        h = hashlib.sha1(src_path.encode("utf-8")).hexdigest()[:8]
        fname = f"local-{h}{os.path.splitext(src_path)[1]}"
        dst_path = os.path.join(MEDIA_DIR, fname)

        try:
            if not os.path.exists(dst_path):
                os.makedirs(os.path.dirname(dst_path), exist_ok=True)
                with open(src_path, "rb") as src, open(dst_path, "wb") as dst:
                    dst.write(src.read())
            rel = os.path.relpath(dst_path, BUILD_DIR).replace("\\", "/")
            print(f"ğŸ“¸ æœ¬åœ°å›¾ç‰‡å·²å¤åˆ¶: {src_path} -> {rel}")
            return rel
        except Exception as e:
            print("âš ï¸  å¤åˆ¶æœ¬åœ°å›¾ç‰‡å¤±è´¥:", src_path, e)
            return None

    # 1) å¤„ç†æ ‡å‡† Markdown å›¾ç‰‡è¯­æ³• ![alt](url "title")
    #    è¿™ä¸ª regex é€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µï¼ˆæ³¨æ„ï¼šè‹¥ url åŒ…å«æœªé…å¯¹çš„æ‹¬å·ï¼Œå¯èƒ½å¤±æ•ˆï¼‰
    md_img_re = re.compile(r'!\[([^\]]*)\]\((\S+?)(?:\s+"[^"]*")?\)')

    def md_repl(m):
        alt = m.group(1)
        url = m.group(2).strip()
        if url.startswith("<") and url.endswith(">"):
            url = url[1:-1]

        if url.lower().startswith("http"):
            local = _download_image_with_cache(url, MEDIA_DIR)
        else:
            local = _copy_local_image(url)
        return f'![{alt}]({local or url})'

    text = md_img_re.sub(md_repl, text)

    # 2) å¤„ç† HTML <img src="..."> çš„æƒ…å†µï¼ˆNotion å¯¼å‡ºæœ‰æ—¶ä¼šç”¨è¿™ç§ï¼‰
    md_img_re = re.compile(r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>')
    def html_repl(m):
        url = m.group(1).strip()
        if url.lower().startswith("http"):
            local = _download_image_with_cache(url, MEDIA_DIR)
            if local:
                # ç”¨ markdown è¯­æ³•æ›¿æ¢ä¸ºæ™®é€šå›¾ç‰‡å¼•ç”¨ï¼ˆpandoc æ›´å®¹æ˜“å¤„ç†ï¼‰
                return f'![]({local})'
            else:
                return m.group(0)
        else:
            return m.group(0)
    text = md_img_re.sub(html_repl, text)

    # å¤„ç† HTML å›¾ç‰‡ <img src="...">
    html_img_re = re.compile(r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>')
    def html_repl(m):
        url = m.group(1).strip()
        if url.lower().startswith("http"):
            local = _download_image_with_cache(url, MEDIA_DIR)
        else:
            local = _copy_local_image(url)
        return f'![]({local or url})'

    text = html_img_re.sub(html_repl, text)
    out_md = os.path.join(BUILD_DIR, os.path.basename(md_path))
    with open(out_md, "w", encoding="utf-8") as f:
        f.write(text)

    return out_md

# Pandoc Markdown â†’ LaTeX
def md_to_latex(md_file):
    """
    å°† Markdown è½¬ LaTeXï¼Œä¿è¯å›¾ç‰‡è·¯å¾„å¯ç›´æ¥åœ¨ build/book.tex ä¸­ç”Ÿæˆ PDFã€‚
    """
    # 1. ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¹¶æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„
    tmp_md = _localize_images_in_md(md_file)

    # 2. è°ƒç”¨ Pandoc è½¬ LaTeX
    result = subprocess.run(
        [
            "pandoc", tmp_md,
            "-f", "markdown",
            "-t", "latex",
            "--metadata", "link-citations=false",
            "--no-highlight",
            "--top-level-division=section",
            "--wrap=none",
            "--listings"
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        encoding="utf-8"
    )
    if result.returncode != 0:
        print(f"Pandoc è½¬ LaTeX å‡ºé”™: {result.stderr}")
        return ""
    tex = result.stdout

    # 3. ç§»é™¤æ‰€æœ‰ \label{...} é˜²æ­¢ä¸­æ–‡æŠ¥é”™
    tex = re.sub(r'\\label\{.*?\}', '', tex)

    # 4. æ›¿æ¢ç‰¹æ®Šç¬¦å· â–ª â†’ \textbullet{}
    tex = tex.replace("â–ª", "\\textbullet{}")

    # 5. ä¿®æ­£ \includegraphicsï¼Œç»Ÿä¸€åŒ…è£¹ä¸€å±‚ \pandocbounded
    def fix_graphics(match):
        # åŸè·¯å¾„
        path = match.group(2).strip()

        # è·¯å¾„è½¬ä¸ºç»å¯¹è·¯å¾„å†ç›¸å¯¹äº BASE_DIR
        abs_path = os.path.abspath(os.path.join(BUILD_DIR, path)) if not os.path.isabs(path) else path
        rel_path = os.path.relpath(abs_path, BASE_DIR).replace("\\", "/")
        # è½¬ä¹‰ä¸‹åˆ’çº¿
        rel_path = rel_path.replace("_", "\\_")

        # å›ºå®šé€‰é¡¹
        options = "[keepaspectratio,width=\\linewidth]"

        # è¿”å›å•å±‚ pandocbounded åŒ…è£¹
        return f"\\includegraphics{options}{{{rel_path}}}"

    tex = re.sub(
        r'\\includegraphics(\[.*?\])\{(.*?)\}',
        fix_graphics,
        tex
    )

    return tex

# æ¸²æŸ“ LaTeX æ¨¡æ¿
def render_tex(parts):
    template_path = os.path.join(BASE_DIR, "template", "template.tex")
    with open(template_path, "r", encoding="utf-8") as f:
        template_content = f.read()
    env = Environment(
        block_start_string = '<%',
        block_end_string = '%>',
        variable_start_string = '<<',
        variable_end_string = '>>',
        comment_start_string = '<#',
        comment_end_string = '#>',
        autoescape = False
    )
    template = env.from_string(template_content)
    return template.render(parts=parts)

def main():
    os.makedirs(os.path.join(BASE_DIR, "build"), exist_ok=True)
    parts = collect_parts()

    # ç”Ÿæˆ LaTeX å†…å®¹
    for part in parts:
        part["readme_tex"] = md_to_latex(part["readme"]) if part["readme"] else ""
        chapters_data = []
        for i in range(len(part["chapters"])):
            chap = part["chapters"][i]# chap æ˜¯ç« èŠ‚(md)çš„å®Œæ•´è·¯å¾„
            if part["chapter_titles"]:
                title = part["chapter_titles"][i]
            else:
                file_name = os.path.splitext(os.path.basename(chap))[0]
                title = file_name
            tex = md_to_latex(chap)
            # è·å–ç« èŠ‚æ ‡é¢˜
            # first_line = tex.strip().split("\n")[0]
            # title = first_line.replace("\\section{", "").replace("}", "") if first_line.startswith("\\section") else file_name
            
            chapters_data.append({"title": title, "tex": tex})
        part["chapters_data"] = chapters_data

    tex_content = render_tex(parts)
    with open(OUTPUT_TEX, "w", encoding="utf-8") as f:
        f.write(tex_content)

    # XeLaTeX ç”Ÿæˆ PDF
    subprocess.run([
        "xelatex",
        "-interaction=nonstopmode",
        "-output-directory", os.path.join(BASE_DIR, "build"),
        OUTPUT_TEX
    ])
    generated_pdf = os.path.join(BASE_DIR, "build", "book.pdf")
    if os.path.exists(generated_pdf):
        os.replace(generated_pdf, OUTPUT_PDF)
        print(f"PDF å·²ç”Ÿæˆ: {OUTPUT_PDF}")

if __name__ == "__main__":
    main()
